{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624600d8-e999-4450-a15e-81b797a17bb7",
   "metadata": {},
   "source": [
    "# Support Vector Machines in Python, From Start To Finish\n",
    "\n",
    "In this lesson we will built this **Support Vector Machine** for **classification** (shown below) using **scikit-learn** and the **Radial Basis Function (RBF) Kernel**. Our training data set contains continuous and categorical data from the **[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)** to predict whether or not a patient has **[heart disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)**.\n",
    "\n",
    "<img src=\"./svm.png\" alt=\"A Support Vector Machine\" style=\"width: 600px;\">\n",
    "\n",
    "**Support Vector Machines** are one of the best machine learning methods when getting the correct answer is a higher priorty than understanding why you get the correct answer, and they work really well with relatively small datasets.\n",
    "\n",
    "In this lesson you will learn about...\n",
    "\n",
    "- **[Importing the Data From a File](#download-the-data)**\n",
    "\n",
    "- **[Missing Data](#identify-and-deal-with-missing-data)**\n",
    "    - Identifying Missing Data\n",
    "    - Dealing with Missing Data\n",
    "    \n",
    "\n",
    "- **[Formatting the Data for Support Vector Machines](#format-the-data)**\n",
    "    - Split data into Dependent and Independent Variables\n",
    "    - One-Hot-Encoding\n",
    "    - Centering and Scaling the Data\n",
    "    \n",
    "\n",
    "- **[Building a Preliminary Support Vector Machine](#build-svm)**\n",
    "\n",
    "- **[Opimizing Parameters with Cross Validation](#optimize-svm)**\n",
    "    - Cross Validation For Finding the Best Values for Gamma and Regularization\n",
    "\n",
    "\n",
    "- **[Building, Evaluating, Drawing and Interpreting the Final Support Vector Machine](#draw-svm)**\n",
    "\n",
    "#### NOTE:\n",
    "This tutorial assumes that you are already know the basics of coding in **Python** and are familiar with the theory behind **Support Vector Machines**, the **Radial Basis Function (RBF)**, **Regularization**, **Cross Validation** and **Confusion Matrices**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf697e0-5462-4385-b760-bd617a5fc44c",
   "metadata": {},
   "source": [
    "#### Also Note:\n",
    "Before running any Python code, I encourage you to pause the video first. That way, if something goes wrong and you get an error, you have time to contemplate the mistake and correct it before the video plows on to the next topic.\n",
    "\n",
    "I also strongly encourage you to play around with the code and try some of the alternative\n",
    "methods that I have described before moving on. Playing with the code is the best way to learn from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b446dfe-d797-44c7-a277-1e97c2270476",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19066eee-4168-4bc3-aca8-5f9c7879f1c5",
   "metadata": {},
   "source": [
    "# Task 1: Import the modules that will do all the work\n",
    "The very first thing we do is load in a bunch of python modules. Python, itself, just gives us a basic programming language. These modules give us extra functionality to import the data, clean it up and format it, and then build, evaluate and draw the support vector machine. \n",
    "\n",
    "**NOTE:** You will need **Python 3** and have at least these versions for each of the following modules: \n",
    "- pandas >= 0.25.1\n",
    "- numpy >= 1.17.2\n",
    "- sklearn >= 0.22.1\n",
    " \n",
    "If you installed **Python 3** with [Anaconda](https://www.anaconda.com/) can check which version you have with the command: `conda list`. If, for example, your version of `scikit-learn` is older than 0.22.1, then the easiest thing to do is just update all of your **Anaconda** packages with the following command: `conda update --all`. However, if only want to update `scikit-learn`, then you can run this command: `conda install scikit-learn=0.22.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0071d262-015c-4d29-a8f4-4df88117f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pandas is used to load and manipulate data and for One-Hot Encoding\n",
    "import numpy as np # numpy is used to calculate the mean and standard deviation\n",
    "import matplotlib.pyplot as plt # matplotlib is for drawing graphs\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from sklearn.model_selection import train_test_split # split  data into training and testing sets\n",
    "from sklearn.preprocessing import scale # scale and center data\n",
    "from sklearn.svm import SVC # this will make a support vector machine for classificaiton\n",
    "from sklearn.model_selection import GridSearchCV # this will do cross validation\n",
    "from sklearn.metrics import confusion_matrix # this creates a confusion matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix  old version of scikit learn in original lab \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA # to perform PCA to plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95edb3d8-c753-4129-9e81-7cec8db88d64",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe03886-6cb5-4e67-b1c0-430666b17340",
   "metadata": {},
   "source": [
    "<a id=\"download-the-data\"></a>\n",
    "# Task 2: Import the data\n",
    "Now we load in a dataset from the **[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)**. </br>\n",
    "Specifically, we are going to use the **[Heart Disease Dataset](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)**. </br>\n",
    "This dataset will allow us to predict if someone has heart disease based on their sex, age, blood pressure and a variety of other metrics.\n",
    "</br>\n",
    "</br>\n",
    "**NOTE:** When **pandas** (**pd**) reads in data, it returns a **data frame**, which is a lot like a spreadsheet. The data are organized in rows and columns and each row can contain a mixture of text and numbers. The standard variable name for a **data frame** is the initials **df**, and that is what we will use here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e1fe93-19f1-460b-be9e-4b48c9b32438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed.cleveland.data\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4870c7a-0803-437d-82fd-5c0271d0944e",
   "metadata": {},
   "source": [
    "Now that we have loaded the data into a **data frame** called **df**, let's look at the first five rows using the `head()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e05a597-089b-4244-b813-1520656a101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2      3      4    5    6      7    8    9    10   11   12  13\n",
       "0  63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.3  3.0  0.0  6.0   0\n",
       "1  67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  3.0  3.0   2\n",
       "2  67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.6  2.0  2.0  7.0   1\n",
       "3  37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.5  3.0  0.0  3.0   0\n",
       "4  41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.4  1.0  0.0  3.0   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0af9760-e174-4cf1-bfff-424fb111b7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "               6           7           8           9           10          13  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.937294  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    1.228536  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    2.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    4.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25567014-10ea-41af-a211-e49c8064b9fa",
   "metadata": {},
   "source": [
    "We see that instead of nice column names, we just have column numbers.  Since nice column names would make it easier to know how to format the data, let's replace the column numbers with the following column names:\n",
    "- **age**,\n",
    "- **sex**,\n",
    "- **cp**, chest pain\n",
    "- **restbp**, resting blood pressure (in mm Hg)\n",
    "- **chol**, serum cholesterol in mg/dl\n",
    "- **fbs**, fasting blood sugar\n",
    "- **restecg**, resting electrocardiographic results\n",
    "- **thalach**,  maximum heart rate achieved\n",
    "- **exang**, exercise induced angina\n",
    "- **oldpeak**, ST depression induced by exercise relative to rest\n",
    "- **slope**, the slope of the peak exercise ST segment.\n",
    "- **ca**, number of major vessels (0-3) colored by fluoroscopy\n",
    "- **thal**, this is short of thalium heart scan.\n",
    "- **hd**, diagnosis of heart disease, the predicted attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04b9591-0af6-4104-bf42-c3151e72f90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  restbp   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0   145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0   160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0   120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0   130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0   130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  hd  \n",
       "0    3.0  0.0  6.0   0  \n",
       "1    2.0  3.0  3.0   2  \n",
       "2    2.0  2.0  7.0   1  \n",
       "3    3.0  0.0  3.0   0  \n",
       "4    1.0  0.0  3.0   0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['age',\n",
    "              'sex',\n",
    "              'cp',\n",
    "              'restbp',\n",
    "              'chol',\n",
    "              'fbs',\n",
    "              'restecg',\n",
    "              'thalach',\n",
    "              'exang',\n",
    "              'oldpeak',\n",
    "              'slope',\n",
    "              'ca',\n",
    "              'thal',\n",
    "              'hd']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34b2c5-79e5-45a3-85cb-e549594df244",
   "metadata": {},
   "source": [
    "Hooray! We have replaced the column numbers with nice, easy to remember names. Now that we have the data in a **data frame** called **df**, we are ready to identify and deal with **Missing Data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f10f5-b5c4-41d6-8f61-2b98350106fe",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e795d-0c91-4838-8ae1-c25acc781e0b",
   "metadata": {},
   "source": [
    "<a id=\"identify-and-deal-with-missing-data\"></a>\n",
    "# Task 3: Missing Data Part 1: Identifying Missing Data\n",
    "Unfortunately, the biggest part of any data analysis project is making sure that the data is correctly formatted and fixing it when it is not. The first part of this process is dealing with **Missing Data**.\n",
    "\n",
    "**Missing Data** is simply a blank space or surrogate value that indicates that we failed to collect data for one of the features. For example, if we forgot to ask someone's age, or forgot to write it down, then we would have a blank space in the dataset for that person's **age**.\n",
    "\n",
    "There are two main ways to deal with missing data:\n",
    "1. We can remove the rows that contain missing data from the dataset. This is relatively easy to do, but it wastes all of the other values that we collected. How a big of a waste this is depends on how important this missing value is for classification. For example, if we are missing a value for **age**, and **age** is not useful for classifying if people have heart disease or not, then it would be a shame to throw out all of someone's data just because we do not have their **age**.\n",
    "2. We can **impute** the values that are missing. In this context **impute** is just a fancy way of saying \"we can make an educated guess about about what the value should be\". Continuing our example where we are missing a value for **age**, instead of throwing out the entire row of data, we can fill the missing value with the average age or the median age, or use some other, more sophisticated approach, to guess at an appropriate value.\n",
    "\n",
    "In this section, we'll focus on identifying missing values in the dataset and dealing with them. \n",
    "\n",
    "First, let's see what sort of data is in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f92136-3a52-43bc-9f8a-606adb376850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        float64\n",
       "sex        float64\n",
       "cp         float64\n",
       "restbp     float64\n",
       "chol       float64\n",
       "fbs        float64\n",
       "restecg    float64\n",
       "thalach    float64\n",
       "exang      float64\n",
       "oldpeak    float64\n",
       "slope      float64\n",
       "ca          object\n",
       "thal        object\n",
       "hd           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f11820-7b22-41f4-84b6-1203f0d875ab",
   "metadata": {},
   "source": [
    "We see that that they are almost all `float64`, however, two columns, **ca** and **thal**, have the `object` type and one column, **hd** has `int64`.\n",
    "\n",
    "The fact that the **ca** and **thal** columns have `object` data types suggests there is something funny going on in them. `object` datatypes are used when there are mixtures of things, like a mixture of numbers and letters. </br>\n",
    "In theory, both **ca** and **thal** should just have a few values representing different categories, so let's investigate what's going on by printing out their unique values. We'll start with **ca**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e35dcb-989e-422f-ae43-e18a5bd139be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0', '3.0', '2.0', '1.0', '?'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6cac9-3fe7-45c9-830a-a1f85122fea9",
   "metadata": {},
   "source": [
    "We see that ca contains numbers (0.0, 3.0, 2.0 and 1.0) and questions marks (?). The numbers represent the number of blood vessels that we lit up by fluoroscopy and the question marks represent missing data.\n",
    "\n",
    "Now let's look at the unique values in thal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e83496d-f78a-410f-8f78-b016bb4a2745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6.0', '3.0', '7.0', '?'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thal'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c15021-2b24-4dd5-944d-027175938858",
   "metadata": {},
   "source": [
    "Again, thal also contains a mixture of numbers, representing the different diagnoses from the thalium heart scan, and question marks, which represent missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79873d7-8c27-40ab-9a50-e9544b9425fa",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7f593-3bfc-462c-93bb-35efcf802652",
   "metadata": {},
   "source": [
    "# Task 4: Missing Data Part 2: Dealing With Missing Data\n",
    "\n",
    "Since scikit-learn's support vector machines do not support datasets with missing values, we need to figure out what to do these question marks. We can either delete these patients from the training dataset, or impute values for the missing data. </br>\n",
    "First let's see how many rows contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7b49d0f-74c2-4ea8-916f-87106d184797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[(df['ca']=='?')|(df['thal']=='?')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884714a-87cc-4373-9fa1-6325a6c7adb7",
   "metadata": {},
   "source": [
    "Since only 6 rows have missing values, let's look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50140b78-5d28-4085-817b-ab3f51539748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  restbp   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0   128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "166  52.0  1.0  3.0   138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0   132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "266  52.0  1.0  4.0   128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "287  58.0  1.0  2.0   125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0   138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  hd  \n",
       "87     1.0  0.0    ?   0  \n",
       "166    1.0    ?  3.0   0  \n",
       "192    2.0    ?  7.0   1  \n",
       "266    2.0  0.0    ?   2  \n",
       "287    2.0    ?  7.0   0  \n",
       "302    1.0    ?  3.0   0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['ca'] == '?') | (df['thal'] == '?')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e072d98-c957-4453-b60f-559325c5dbbb",
   "metadata": {},
   "source": [
    "Now let's count the number of rows in the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53f8c72a-684c-48b6-b92c-6f3f89ede17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f886698-822f-4337-a60b-f2faf7dafced",
   "metadata": {},
   "source": [
    "So 6 of the 303 rows, or 2%, contain missing values. Since 303 - 6 = 297, and 297 is plenty of data to build a support vector machine, we will remove the rows with missing values, rather than try to impute their values. We do this by selecting all of the rows that do not contain question marks in either the ca or thal columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ade4fdf3-8bf6-4c56-908f-48456b4c3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing=df.loc[(df['ca']!='?') & (df['thal']!='?')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf8eaa-e43a-4a59-9471-6516cec2eb4a",
   "metadata": {},
   "source": [
    "Since `df_no_missing` has **6** fewer rows than the original `df`, it should have **297** rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17fb5041-c3a8-4603-b6f5-f6eae9598b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_no_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305b3fc-72dc-4a6c-b1c9-1608201a85a2",
   "metadata": {},
   "source": [
    "Hooray! The math works out. However, we can also make sure **ca** no longer contains question marks by printing its unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c30ea57b-5322-4a27-aa20-0691570b88d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0', '3.0', '2.0', '1.0'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_missing['ca'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fa52a-d922-4984-9534-9dbd994fdc54",
   "metadata": {},
   "source": [
    "And we can also do the same thing for **thal**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84f6a75a-9629-4296-969d-09b47e8f71d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6.0', '3.0', '7.0'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_missing['thal'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774cdaa4-4507-431a-9b6e-7ac11cd99dd2",
   "metadata": {},
   "source": [
    "BAM! We have verified that `df_no_missing` does not contain any missing values. **NOTE:** **ca** and **thal** still have the `object` data type. That's OK. Now we are ready to format the data for making a **Support Vector Machine**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cfa488-77d9-4938-945a-9cfe779cb1a8",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef0f9e-57b1-4b63-8036-8e315af5b68b",
   "metadata": {},
   "source": [
    "<a id=\"format-the-data\"></a>\n",
    "# Task 5: Format Data Part 1: Split the Data into Dependent and Independent Variables\n",
    "\n",
    "Now that we have taken care of the missing data, we are ready to start formatting the data for making a **Support Vector Machine**.\n",
    "\n",
    "The first step is to split the data into two parts:\n",
    "1. The columns of data that we will use to make classifications\n",
    "2. The column of data that we want to predict.\n",
    "\n",
    "We will use the conventional notation of `X` (capital **X**) to represent the columns of data that we will use to make classifications and `y` (lower case **y**) to represent the thing we want to predict. In this case, we want to predict **hd** (heart disease).\n",
    "\n",
    "**NOTE:** In the code below we are using `copy()` to copy the data *by value*. **By default, pandas uses copy by reference**. Using `copy()` ensures that the original data `df_no_missing` is not modified when we modify `X` or `y`. In other words, if we make a mistake when we are formatting the columns for support vector machines, we can just re-copy `df_no_missing`, rather than have to reload the original data and  remove the missing values etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2db24f4-45fc-4877-bb00-df0a95a28ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  restbp   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0   145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0   160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0   120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0   130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0   130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  \n",
       "0    3.0  0.0  6.0  \n",
       "1    2.0  3.0  3.0  \n",
       "2    2.0  2.0  7.0  \n",
       "3    3.0  0.0  3.0  \n",
       "4    1.0  0.0  3.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df_no_missing.drop('hd',axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8965aee7-25e6-4e38-9abe-d5d166988bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: hd, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_no_missing['hd'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7cf636-3012-4622-8448-ff8575e6ac61",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4c82e-6932-48ff-9299-fb2a56bf1e57",
   "metadata": {},
   "source": [
    "<a id=\"one-hot-encoding\"></a>\n",
    "# Task 6: Format the Data Part 2: One-Hot Encoding\n",
    "\n",
    "Now that we have split the data frame into two pieces, `X`, which contains the data we will use to make, or predict, classifications, and `y`, which contains the known classifications in our training dataset, we need to take a closer look at the variables in `X`. The list bellow tells us what each variable represents and the type of data (**float** or **categorical**) it should contain:\n",
    "\n",
    "- **age**, **Float**\n",
    "- **sex** - **Category**\n",
    "  - 0 = female\n",
    "  - 1 = male\n",
    "- **cp**, chest pain, **Category**\n",
    "  - 1 = typical angina,\n",
    "  - 2 = atypical angina,\n",
    "  - 3 = non-anginal pain,\n",
    "  - 4 = asymptomatic\n",
    "- **restbp**, resting blood pressure (in mm Hg), **Float**\n",
    "- **chol**, serum cholesterol in mg/dl, **Float**\n",
    "- **fbs**, fasting blood sugar, **Category**\n",
    "  - 0 = >=120 mg/dl\n",
    "  - 1 = <120 mg/dl\n",
    "- **restecg**, resting electrocardiographic results, **Category**\n",
    "  - 1 = normal\n",
    "  - 2 = having ST-T wave abnormality\n",
    "  - 3 = showing probable or definite left ventricular hypertrophy\n",
    "- **thalach**,  maximum heart rate achieved, **Float**\n",
    "- **exang**, exercise induced angina, **Category**\n",
    "  - 0 = no\n",
    "  - 1 = yes\n",
    "- **oldpeak**, ST depression induced by exercise relative to rest. **Float**\n",
    "- **slope**, the slope of the peak exercise ST segment, **Category**\n",
    "  - 1 = upsloping\n",
    "  - 2 = flat\n",
    "  - 3 = downsloping\n",
    "- **ca**, number of major vessels (0-3) colored by fluoroscopy, **Float**\n",
    "- **thal**, thalium heart scan, **Category**\n",
    "  - 3 = normal (no cold spots)\n",
    "  - 6 = fixed defect (cold spots during rest and exercise)\n",
    "  - 7 = reversible defect (when cold spots only appear during exercise)\n",
    "\n",
    "Now, just to review, let's look at the data types in `X` to remember how python is seeing the data right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9878ca3e-f006-4f71-be51-f5b2880f869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        float64\n",
       "sex        float64\n",
       "cp         float64\n",
       "restbp     float64\n",
       "chol       float64\n",
       "fbs        float64\n",
       "restecg    float64\n",
       "thalach    float64\n",
       "exang      float64\n",
       "oldpeak    float64\n",
       "slope      float64\n",
       "ca          object\n",
       "thal        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76423c-7682-443b-bbbd-111a2cec098d",
   "metadata": {},
   "source": [
    "So, we see that **age**, **restbp**, **chol** and **thalach** are all `float64`, which is good, because we want them to be floating point numbers. All of the other columns, however, need to be inspected to make sure they only contain reasonable values, and some of them need to change. This is because, while **scikit learn Support Vector Machines** natively support continuous data, like resting blood preasure (**restbp**) and maximum heart rate (**thalach**), they do not natively support categorical data, like chest pain (**cp**), which contains 4 different categories. Thus, in order to use categorical data with **scikit learn Support Vector Machines**, we have to use a trick that converts a column of categorical data into multiple columns of binary values. This trick is called **One-Hot Encoding**.\n",
    "\n",
    "At this point you may be wondering, \"what's wrong with treating categorical data like continuous data?\" To answer that question, let's look at an example: For the **cp** (chest pain) column, we have 4 options:\n",
    "1. typical angina,\n",
    "2. atypical angina,\n",
    "3. non-anginal pain,\n",
    "4. asymptomatic\n",
    "\n",
    "If we treated these values, 1, 2, 3 and 4, like continuous data, then we would assume that 4, which means \"asymptomatic\", is more similar to 3, which means \"non-anginal pain\", than it is to 1 or 2, which are other types of chest pain. Thus, the support vector machine would be more likely to cluster the patients with 4s and 3s together than the patients with 4s and 1s together. In contrast, if we treat these numbers like categorical data, then we treat each one a separate category that is no more or less similar to any of the other categories. Thus, the likelihood of clustering patients with 4s with 3s is the same as clustering 4s with 1s, and that approach is more reasonable.\n",
    "\n",
    "Now let's inspect and, if needed, convert the columns that contain categorical and integer data into the correct datatypes. We'll start with **cp** (chest pain) by inspecting all of its unique values:\n",
    "<!-- We'll start with the three colunms that should only contain 0s and 1s. **sex**. First, let's make sure it only contains `0` (for **female**) and `1` (for **male**). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "008a50f4-fee8-4bce-9ef1-abb7fba430c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4., 3., 2.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['cp'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58438b9-6895-4b03-9a90-2390ad172bbd",
   "metadata": {},
   "source": [
    "So, the good news is that **cp** only contains the values it is supposed to contain, so we will convert it, using **One-Hot Encoding**, into a series of columns that only contains **0s** and **1s**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab02c3c-12b0-41cb-9362-1c6ba68ef8d6",
   "metadata": {},
   "source": [
    "<!-- Now we need to deal with **cp** (chest pain), **restecg** (resting electrocardiographic results), **slope** (the slope of the peak exercise ST segment) and **thal** (thalium heart scan).\n",
    " -->\n",
    "**NOTE:** There are many different ways to do **One-Hot Encoding** in Python. Two of the more popular methods are `ColumnTransformer()` (from **scikit-learn**) and `get_dummies()` (from **pandas**), and the both methods have pros and cons. `ColumnTransformer()` has a very cool feature where it creates a persistent function that can validate data that you get in the future. For example, if you build your **Support Vector Machine** using a categorical variable **favorite color** that has **red**, **blue** and **green** options, then `ColumnTransformer()` can remember those options and later on when your **Support Vector Machine** is being used in a production system, if someone says their favorite color is **orange**, then `ColumnTransformer()` can throw an error or handle the situation in some other nice way. The downside of `ColumnTransformer()` is that it turns your data into an array and looses all of the column names, making it harder to verify that your usage of `ColumnTransformer()` worked as you intended it to. In contrast, `get_dummies()` leaves your data in a dataframe and retains the column names, making it much easier to verify that it worked as intended. However, it does not have the persistent behavior that `ColumnTransformer()` has. So, for the sake of learning how **One-Hot Encoding** works, I prefer to use `get_dummies()`. However, once you are comfortable with **One-Hot Encoding**, I encourage you to investigate using `ColumnTransformer()`.\n",
    "\n",
    "First, before we commit to converting **cp** with **One-Hot Encoding**, let's just see what happens when we convert **cp** without saving the results. This will just make it easy to see how `get_dummies()` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2b401f9-fa0b-4086-b328-9db01fc17c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  restbp   chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0  63.0  1.0   145.0  233.0  1.0      2.0    150.0    0.0      2.3    3.0   \n",
       "1  67.0  1.0   160.0  286.0  0.0      2.0    108.0    1.0      1.5    2.0   \n",
       "2  67.0  1.0   120.0  229.0  0.0      2.0    129.0    1.0      2.6    2.0   \n",
       "3  37.0  1.0   130.0  250.0  0.0      0.0    187.0    0.0      3.5    3.0   \n",
       "4  41.0  0.0   130.0  204.0  0.0      2.0    172.0    0.0      1.4    1.0   \n",
       "\n",
       "    ca thal  cp_1.0  cp_2.0  cp_3.0  cp_4.0  \n",
       "0  0.0  6.0    True   False   False   False  \n",
       "1  3.0  3.0   False   False   False    True  \n",
       "2  2.0  7.0   False   False   False    True  \n",
       "3  0.0  3.0   False   False    True   False  \n",
       "4  0.0  3.0   False    True   False   False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(X, columns=['cp']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974611bd-df0f-4114-9b46-21662628d092",
   "metadata": {},
   "source": [
    "As we can see in the printout above, get_dummies() puts all of the columns it does not process in the front and it puts cp at the end. It also split cp into 4 columns, just like we expected it. cp_1.0 is 1 for any patient that scored a 1 for chest pain and 0 for all other patients. cp_2.0 is 1 for any patient that scored 2 for chest pain and 0 for all other patients. cp_3.0 is 1 for any patient that scored 3 for chest pain and cp_4.0 is 1 for any patient that scored 4 for chest pain.\n",
    "\n",
    "Now that we see how get_dummies() works, let's use it on the four categorical columns that have more than 2 categories and save the result.\n",
    "\n",
    "NOTE: In practice you should verify all 5 of these columns to make sure they only contain the accepted categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c42aceed-00ac-4e58-8968-463789efd958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>restecg_0.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  restbp   chol  fbs  thalach  exang  oldpeak   ca  cp_1.0  ...  \\\n",
       "0  63.0  1.0   145.0  233.0  1.0    150.0    0.0      2.3  0.0    True  ...   \n",
       "1  67.0  1.0   160.0  286.0  0.0    108.0    1.0      1.5  3.0   False  ...   \n",
       "2  67.0  1.0   120.0  229.0  0.0    129.0    1.0      2.6  2.0   False  ...   \n",
       "3  37.0  1.0   130.0  250.0  0.0    187.0    0.0      3.5  0.0   False  ...   \n",
       "4  41.0  0.0   130.0  204.0  0.0    172.0    0.0      1.4  0.0   False  ...   \n",
       "\n",
       "   cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  slope_1.0  slope_2.0  \\\n",
       "0   False        False        False         True      False      False   \n",
       "1    True        False        False         True      False       True   \n",
       "2    True        False        False         True      False       True   \n",
       "3   False         True        False        False      False      False   \n",
       "4   False        False        False         True       True      False   \n",
       "\n",
       "   slope_3.0  thal_3.0  thal_6.0  thal_7.0  \n",
       "0       True     False      True     False  \n",
       "1      False      True     False     False  \n",
       "2      False     False     False      True  \n",
       "3       True      True     False     False  \n",
       "4      False      True     False     False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded=pd.get_dummies(X, columns=['cp','restecg','slope','thal'])\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ed7d8-97cf-41c6-a178-71dbcd743ef9",
   "metadata": {},
   "source": [
    "Now we need to talk about the **3** categorical columns that only contain **0**s and **1**s: **sex**, **fbs** (fasting blood sugar), and **exang** (exercise induced angina). As we can see, **One-Hot Encoding** converts a column with more than **2** categories, like **cp** (chest pain) into multiple columns of **0**s and **1**s. Since **sex**, **fbs**, and **exang** only have **2** categories and only contain **0**s and **1**s to begin with, we do not have to do anything special to them, so we're done formatting the data for the **Support Vector Machine**.\n",
    "\n",
    "**NOTE:** In practice we would use `unique()` to verify that they only contain **0**s and **1**s, but to save time...trust me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a0530-5c66-4c7d-9318-b24e0021de6e",
   "metadata": {},
   "source": [
    "Now, one last thing before we build a Support Vector Machine. y doesn't just contain 0s and 1s. Instead, it has 5 different levels of heart disease. 0 = no heart disease and 1-4 are various degrees of heart disease. We can see this with unique():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2155764-888d-4200-b63e-92eb3c186d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52b409-48ab-438d-ab52-bd7194c108d2",
   "metadata": {},
   "source": [
    "Since we're only making a support vector machine that does simple classification and only care if someone has heart disease or not, we need to convert all numbers **> 0** to **1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68475b1f-3a20-46c2-8f4c-3094039298c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_not_zero_idx=y>0\n",
    "y[y_not_zero_idx]=1\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391cc54-b3cf-4c5f-be39-54487780e1fc",
   "metadata": {},
   "source": [
    "We have finally finished formatting the data for making a **Support Vector Machine**, so let's do it!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ce29f-af92-4931-94e6-2fa9e0e36153",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
