{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Understand the core components of a Transformer architecture.\n",
    "- Implement a multi-head self-attention mechanism from scratch.\n",
    "- Train and evaluate a Transformer for time series prediction.\n",
    "- Handle preprocessing and scaling for time series data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Transformer?\n",
    "\n",
    "The Transformer architecture was introduced in the paper *\"Attention Is All You Need\"*. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
    "\n",
    "### Key Components:\n",
    "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
    "- **Positional Encoding:** Injects information about the position of input tokens.\n",
    "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
    "- **Feedforward Layers:** Process the attended information.\n",
    "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
    "\n",
    "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
    "\n",
    "**Next:** You will implement parts of this architecture step-by-step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (2.16.2)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-21.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/francd/anaconda3/envs/masterMLpythonGPU/lib/python3.11/site-packages (from requests) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 20:49:40.985789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-06 20:49:41.005508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-06 20:49:41.005535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-06 20:49:41.017825: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-06 20:49:41.752446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 20:54:08.595638: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-06 20:54:08.635430: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 238ms/step - loss: 3.9948\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - loss: 0.1637\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 254ms/step - loss: 0.1590\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 221ms/step - loss: 0.1644\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.1328\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 250ms/step - loss: 0.1939\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 225ms/step - loss: 0.1514\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - loss: 0.1367\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.1193\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.1294\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.1327\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.1439\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 223ms/step - loss: 0.0840\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.0641\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.0977\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.0563\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.0524\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - loss: 0.0486\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0631\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f42748b7e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "# Prepare true values for comparison\n",
    "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot the predictions vs true values\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(true_values, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 3.7312\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - loss: 1.2150\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 217ms/step - loss: 0.7450\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - loss: 0.3813\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.1828\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - loss: 0.0920\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 229ms/step - loss: 0.0493\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 239ms/step - loss: 0.0331\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 217ms/step - loss: 0.0283\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 236ms/step - loss: 0.0214\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 228ms/step - loss: 0.0210\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 251ms/step - loss: 0.0172\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 243ms/step - loss: 0.0168\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - loss: 0.0149\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 238ms/step - loss: 0.0143\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 244ms/step - loss: 0.0199\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 256ms/step - loss: 0.0172\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 240ms/step - loss: 0.0113\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 235ms/step - loss: 0.0093\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 240ms/step - loss: 0.0131\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 5.1619e-04\n",
      "Test loss: 0.0005161946173757315\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "dropout = Dropout(0.5)(flatten) \n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "  \n",
    "# Build the model \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Train the model \n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    " \n",
    "# Evaluate the model \n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 115ms/step - loss: 0.0190\n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - loss: 0.0224\n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 116ms/step - loss: 0.0243\n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - loss: 0.0206\n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.0387\n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - loss: 0.0256\n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 123ms/step - loss: 0.0274\n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 115ms/step - loss: 0.0144\n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 0.0146\n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.0130\n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 0.0215\n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 0.0307\n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 114ms/step - loss: 0.0303\n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 116ms/step - loss: 0.0230\n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 119ms/step - loss: 0.0200\n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 0.0165\n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 0.0254\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 0.0142\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 0.0101\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 0.0132\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.0049\n",
      "Test loss with batch size 16: 0.004904646892100573\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 463ms/step - loss: 0.0083\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 498ms/step - loss: 0.0053\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 488ms/step - loss: 0.0040\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 553ms/step - loss: 0.0037\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 537ms/step - loss: 0.0036\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 506ms/step - loss: 0.0033\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 531ms/step - loss: 0.0046\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 527ms/step - loss: 0.0035\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 503ms/step - loss: 0.0038\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 504ms/step - loss: 0.0032\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 508ms/step - loss: 0.0029\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 541ms/step - loss: 0.0032\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 531ms/step - loss: 0.0031\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 515ms/step - loss: 0.0034\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 490ms/step - loss: 0.0033\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 503ms/step - loss: 0.0035\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 493ms/step - loss: 0.0043\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 507ms/step - loss: 0.0043\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 510ms/step - loss: 0.0037\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 497ms/step - loss: 0.0033\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 7.3962e-04\n",
      "Test loss with batch size 64: 0.0007396201835945249\n"
     ]
    }
   ],
   "source": [
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 0.1034\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 245ms/step - loss: 0.0282\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 255ms/step - loss: 0.0148\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 230ms/step - loss: 0.0107\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 233ms/step - loss: 0.0086\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 223ms/step - loss: 0.0083\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 244ms/step - loss: 0.0061\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 243ms/step - loss: 0.0067\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 252ms/step - loss: 0.0041\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 254ms/step - loss: 0.0042\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 254ms/step - loss: 0.0030\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 273ms/step - loss: 0.0023\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 253ms/step - loss: 0.0028\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 249ms/step - loss: 0.0023\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 272ms/step - loss: 0.0019\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 241ms/step - loss: 0.0027\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 231ms/step - loss: 0.0024\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 228ms/step - loss: 0.0076\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0032\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 224ms/step - loss: 0.0016\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - loss: 7.9769e-04\n",
      "Test loss with tanh activation: 0.0007976897177286446\n"
     ]
    }
   ],
   "source": [
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
